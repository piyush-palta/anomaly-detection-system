{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anomaly based Network Intrusion Detection System.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMLw9zmn_Woy",
        "colab_type": "text"
      },
      "source": [
        "# **Anomaly Detection based Network Intrusion Detection System**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obJmw3SHDnKy",
        "colab_type": "text"
      },
      "source": [
        "### 1. Mount drive to download Datasets \n",
        "Make sure your google drive has atleast 1GB of free space\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyS-monz_Dhn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "791ff356-3a63-4e5b-db6a-2c93bf5a7677"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVg5EClKD1KL",
        "colab_type": "text"
      },
      "source": [
        "### 2. Download and unzip datasets (need to be done only once)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC2HZxkhSWzi",
        "colab_type": "text"
      },
      "source": [
        "Make directory `IDS_Dataset` in your drive and make it the pwd(present working directory)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlDO3fyVPPv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "23fb52b7-67c0-4a2c-9447-ca2e925234f3"
      },
      "source": [
        "%cd /content/gdrive/My\\ Drive\n",
        "%mkdir IDS_Dataset\n",
        "%cd IDS_Dataset/"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n",
            "mkdir: cannot create directory ‘IDS_Dataset’: File exists\n",
            "/content/gdrive/My Drive/IDS_Dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RelU36d9S3E_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bbdc9abc-e83a-470c-a9ca-3015b71e20e5"
      },
      "source": [
        "!wget --no-check-certificate http://kdd.org/cupfiles/KDDCupData/1999/kddcup.data.zip\n",
        "!wget --no-check-certificate http://kdd.org/cupfiles/KDDCupData/1999/kddcup.data_10_percent.zip\n",
        "!wget --no-check-certificate http://kdd.org/cupfiles/KDDCupData/1999/kddcup.newtestdata_10_percent_unlabeled.zip\n",
        "!wget --no-check-certificate http://kdd.org/cupfiles/KDDCupData/1999/kddcup.testdata.unlabeled.zip\n",
        "!wget --no-check-certificate http://kdd.org/cupfiles/KDDCupData/1999/corrected.zip\n",
        "!wget --no-check-certificate http://kdd.org/cupfiles/KDDCupData/1999/kddcup.testdata.unlabeled_10_percent.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-26 21:37:19--  http://kdd.org/cupfiles/KDDCupData/1999/kddcup.data.zip\n",
            "Resolving kdd.org (kdd.org)... 72.10.51.228\n",
            "Connecting to kdd.org (kdd.org)|72.10.51.228|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.kdd.org/cupfiles/KDDCupData/1999/kddcup.data.zip [following]\n",
            "--2020-08-26 21:37:20--  https://www.kdd.org/cupfiles/KDDCupData/1999/kddcup.data.zip\n",
            "Resolving www.kdd.org (www.kdd.org)... 72.10.51.228\n",
            "Connecting to www.kdd.org (www.kdd.org)|72.10.51.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18119640 (17M) [application/zip]\n",
            "Saving to: ‘kddcup.data.zip’\n",
            "\n",
            "kddcup.data.zip     100%[===================>]  17.28M  4.66MB/s    in 4.4s    \n",
            "\n",
            "2020-08-26 21:37:25 (3.93 MB/s) - ‘kddcup.data.zip’ saved [18119640/18119640]\n",
            "\n",
            "--2020-08-26 21:37:25--  http://kdd.org/cupfiles/KDDCupData/1999/kddcup.data_10_percent.zip\n",
            "Resolving kdd.org (kdd.org)... 72.10.51.228\n",
            "Connecting to kdd.org (kdd.org)|72.10.51.228|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.kdd.org/cupfiles/KDDCupData/1999/kddcup.data_10_percent.zip [following]\n",
            "--2020-08-26 21:37:25--  https://www.kdd.org/cupfiles/KDDCupData/1999/kddcup.data_10_percent.zip\n",
            "Resolving www.kdd.org (www.kdd.org)... 72.10.51.228\n",
            "Connecting to www.kdd.org (www.kdd.org)|72.10.51.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2145702 (2.0M) [application/zip]\n",
            "Saving to: ‘kddcup.data_10_percent.zip’\n",
            "\n",
            "kddcup.data_10_perc 100%[===================>]   2.05M  1.14MB/s    in 1.8s    \n",
            "\n",
            "2020-08-26 21:37:27 (1.14 MB/s) - ‘kddcup.data_10_percent.zip’ saved [2145702/2145702]\n",
            "\n",
            "--2020-08-26 21:37:27--  http://kdd.org/cupfiles/KDDCupData/1999/kddcup.newtestdata_10_percent_unlabeled.zip\n",
            "Resolving kdd.org (kdd.org)... 72.10.51.228\n",
            "Connecting to kdd.org (kdd.org)|72.10.51.228|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.kdd.org/cupfiles/KDDCupData/1999/kddcup.newtestdata_10_percent_unlabeled.zip [following]\n",
            "--2020-08-26 21:37:27--  https://www.kdd.org/cupfiles/KDDCupData/1999/kddcup.newtestdata_10_percent_unlabeled.zip\n",
            "Resolving www.kdd.org (www.kdd.org)... 72.10.51.228\n",
            "Connecting to www.kdd.org (www.kdd.org)|72.10.51.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1396249 (1.3M) [application/zip]\n",
            "Saving to: ‘kddcup.newtestdata_10_percent_unlabeled.zip’\n",
            "\n",
            "kddcup.newtestdata_ 100%[===================>]   1.33M   681KB/s    in 2.0s    \n",
            "\n",
            "2020-08-26 21:37:30 (681 KB/s) - ‘kddcup.newtestdata_10_percent_unlabeled.zip’ saved [1396249/1396249]\n",
            "\n",
            "--2020-08-26 21:37:30--  http://kdd.org/cupfiles/KDDCupData/1999/kddcup.testdata.unlabeled.zip\n",
            "Resolving kdd.org (kdd.org)... 72.10.51.228\n",
            "Connecting to kdd.org (kdd.org)|72.10.51.228|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.kdd.org/cupfiles/KDDCupData/1999/kddcup.testdata.unlabeled.zip [following]\n",
            "--2020-08-26 21:37:30--  https://www.kdd.org/cupfiles/KDDCupData/1999/kddcup.testdata.unlabeled.zip\n",
            "Resolving www.kdd.org (www.kdd.org)... 72.10.51.228\n",
            "Connecting to www.kdd.org (www.kdd.org)|72.10.51.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11238836 (11M) [application/zip]\n",
            "Saving to: ‘kddcup.testdata.unlabeled.zip’\n",
            "\n",
            "kddcup.testdata.unl 100%[===================>]  10.72M  3.03MB/s    in 3.9s    \n",
            "\n",
            "2020-08-26 21:37:34 (2.77 MB/s) - ‘kddcup.testdata.unlabeled.zip’ saved [11238836/11238836]\n",
            "\n",
            "--2020-08-26 21:37:34--  http://kdd.org/cupfiles/KDDCupData/1999/corrected.zip\n",
            "Resolving kdd.org (kdd.org)... 72.10.51.228\n",
            "Connecting to kdd.org (kdd.org)|72.10.51.228|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.kdd.org/cupfiles/KDDCupData/1999/corrected.zip [following]\n",
            "--2020-08-26 21:37:35--  https://www.kdd.org/cupfiles/KDDCupData/1999/corrected.zip\n",
            "Resolving www.kdd.org (www.kdd.org)... 72.10.51.228\n",
            "Connecting to www.kdd.org (www.kdd.org)|72.10.51.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1588201 (1.5M) [application/zip]\n",
            "Saving to: ‘corrected.zip’\n",
            "\n",
            "corrected.zip       100%[===================>]   1.51M   914KB/s    in 1.7s    \n",
            "\n",
            "2020-08-26 21:37:37 (914 KB/s) - ‘corrected.zip’ saved [1588201/1588201]\n",
            "\n",
            "--2020-08-26 21:37:37--  http://kdd.org/cupfiles/KDDCupData/1999/kddcup.testdata.unlabeled_10_percent.zip\n",
            "Resolving kdd.org (kdd.org)... 72.10.51.228\n",
            "Connecting to kdd.org (kdd.org)|72.10.51.228|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.kdd.org/cupfiles/KDDCupData/1999/kddcup.testdata.unlabeled_10_percent.zip [following]\n",
            "--2020-08-26 21:37:37--  https://www.kdd.org/cupfiles/KDDCupData/1999/kddcup.testdata.unlabeled_10_percent.zip\n",
            "Resolving www.kdd.org (www.kdd.org)... 72.10.51.228\n",
            "Connecting to www.kdd.org (www.kdd.org)|72.10.51.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1387552 (1.3M) [application/zip]\n",
            "Saving to: ‘kddcup.testdata.unlabeled_10_percent.zip’\n",
            "\n",
            "kddcup.testdata.unl 100%[===================>]   1.32M   796KB/s    in 1.7s    \n",
            "\n",
            "2020-08-26 21:37:39 (796 KB/s) - ‘kddcup.testdata.unlabeled_10_percent.zip’ saved [1387552/1387552]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfGaWbibszai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e6e4e0a8-edda-4811-caeb-64fd553b4331"
      },
      "source": [
        "!unzip kddcup.data.zip -d data\n",
        "!unzip kddcup.data_10_percent.zip -d data\n",
        "!unzip kddcup.newtestdata_10_percent_unlabeled.zip -d data\n",
        "!unzip kddcup.testdata.unlabeled.zip -d data\n",
        "!unzip corrected.zip -d data\n",
        "!unzip kddcup.testdata.unlabeled_10_percent.zip -d data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  kddcup.data.zip\n",
            "  inflating: data/kddcup.data.txt    \n",
            "Archive:  kddcup.data_10_percent.zip\n",
            "  inflating: data/kddcup.data_10_percent.txt  \n",
            "Archive:  kddcup.newtestdata_10_percent_unlabeled.zip\n",
            "  inflating: data/kddcup.newtestdata_10_percent_unlabeled.txt  \n",
            "Archive:  kddcup.testdata.unlabeled.zip\n",
            "  inflating: data/kddcup.testdata.unlabeled.txt  \n",
            "Archive:  corrected.zip\n",
            "  inflating: data/corrected          \n",
            "Archive:  kddcup.testdata.unlabeled_10_percent.zip\n",
            "  inflating: data/kddcup.testdata.unlabeled_10_percent.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uusRFZSw1DbT",
        "colab_type": "text"
      },
      "source": [
        "### 3. Reading Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4JtgFTBsT65",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "514174be-a97b-4eba-9780-ae99c88f14c5"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset_head = ['duration','protocol_type','service','src_bytes','dst_bytes','flag','land','wrong_fragment','urgent',\n",
        "'hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root','num_file_creations',\n",
        "'num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','serror_rate',\n",
        "'rerror_rate','same_srv_rate','diff_srv_rate','srv_count','srv_serror_rate','srv_rerror_rate','srv_diff_host_rate',\n",
        "'dst_host_count','dst_host_srv_count','dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate',\n",
        "'dst_host_srv_diff_host_rate','dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate','class']\n",
        "\n",
        "train = pd.read_csv (r'/content/gdrive/My Drive/IDS_Dataset/data/kddcup.data.txt', header = None, nrows=4817099)\n",
        "test = pd.read_csv (r'/content/gdrive/My Drive/IDS_Dataset/data/kddcup.data_10_percent.txt', header = None, nrows=485797)\n",
        "\n",
        "train.columns = dataset_head\n",
        "test.columns = dataset_head\n",
        "\n",
        "print(train.head())\n",
        "print(test.tail())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   duration protocol_type  ... dst_host_srv_rerror_rate    class\n",
            "0         0           tcp  ...                      0.0  normal.\n",
            "1         0           tcp  ...                      0.0  normal.\n",
            "2         0           tcp  ...                      0.0  normal.\n",
            "3         0           tcp  ...                      0.0  normal.\n",
            "4         0           tcp  ...                      0.0  normal.\n",
            "\n",
            "[5 rows x 42 columns]\n",
            "        duration protocol_type  ... dst_host_srv_rerror_rate     class\n",
            "485792         0           tcp  ...                      0.0  neptune.\n",
            "485793         0           tcp  ...                      0.0  neptune.\n",
            "485794         0           tcp  ...                      0.0  neptune.\n",
            "485795         0           tcp  ...                      0.0  neptune.\n",
            "485796         0           tcp  ...                      0.0  neptune.\n",
            "\n",
            "[5 rows x 42 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwfkZyM_0x36",
        "colab_type": "text"
      },
      "source": [
        "### 4. Preprocessing\n",
        "Prepocessing of dataset is important to get the dataset in desired format. It also includes converting non-number values to numbers using Label Encoding\n",
        "\n",
        "P.S. Here we can use two types of methods, Simple Label Encoding & One Hot Encoder. Implementation of both has been done, you can try either one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1iFExuGugvJ",
        "colab_type": "text"
      },
      "source": [
        " **Label Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tng4W_fJufzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "for column in train.columns:\n",
        "    if train[column].dtype == type(object):\n",
        "        train[column] = le.fit_transform(train[column])\n",
        "\n",
        "for column in test.columns:\n",
        "    if test[column].dtype == type(object):\n",
        "        test[column] = le.fit_transform(test[column])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O5CzIwaKixL3"
      },
      "source": [
        " **One Hot Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PQD3MT8izrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder()\n",
        "for column in train.columns:\n",
        "    if train[column].dtype == type(object):\n",
        "        train[column] = ohe.fit_transform(train[column])\n",
        "\n",
        "for column in test.columns:\n",
        "    if test[column].dtype == type(object):\n",
        "        test[column] = ohe.fit_transform(test[column])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9MMcdmUvmRV",
        "colab_type": "text"
      },
      "source": [
        "**Split Train & Test dataset into X and Y**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHkKuwjMvpdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Since last column is the labels, we are separating them as X and Y, \n",
        "# X are the features and Y is the assigned labels of threat\n",
        "\n",
        "trainX = train.iloc[:,:41]\n",
        "trainY = train.iloc[:,-1]\n",
        "\n",
        "testX = test.iloc[:,:41]\n",
        "testY = test.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryoq9WNEieoX",
        "colab_type": "text"
      },
      "source": [
        "### 5. Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnxJQdPBKqZF",
        "colab_type": "text"
      },
      "source": [
        "**Random Forest Classifier**\n",
        "\n",
        "Random Forest Classifier is an ensemble tree-based learning algorithm. It is a set of decision trees from randomly selected subset of training set. It aggregates the output from different decision trees to decide the final output result.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeGsxLomyKis",
        "colab_type": "text"
      },
      "source": [
        "* Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAvwBdp6a3BX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "5810fa4a-8d66-44db-d336-b5233328ed2d"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#Create a RandomForest Classifier\n",
        "RFclf = RandomForestClassifier(n_estimators=100, n_jobs=-1)  # n_estimators refers to the number of trees in the forest\n",
        "#You can increase the n_estimators for better accuracy, training time will be increased tho\n",
        "\n",
        "#Train the model using the training dataset\n",
        "RFclf.fit(trainX,trainY) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAvnkhT7yRlm",
        "colab_type": "text"
      },
      "source": [
        "* Predicting the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ijE_xwvlO3Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6758cb70-fbe7-4fe4-a646-1ad9ff76cbbb"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predrf = RFclf.predict(testX) #Predicting on the test dataset\n",
        "print(accuracy_score(predrf, testY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9987505068989722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a7SUnVkPGYl8"
      },
      "source": [
        "**Logistic Regression**\n",
        "\n",
        "Logistic regression is a classification algorithm used to assign observations to a discrete set of classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h99tlUyrGYmI"
      },
      "source": [
        "* Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5f6bsjLeGYmK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "d17c304b-b66a-40b7-b5ae-6bc8b8af2eec"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "#Create a Logistic Regression \n",
        "lrclf = LogisticRegression(solver='sag', n_jobs=-1, verbose=1, max_iter=50)  # C is the regularization parameter\n",
        "\n",
        "#Train the model using the training dataset\n",
        "lrclf.fit(testX,testY) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=250)]: Using backend ThreadingBackend with 250 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max_iter reached after 282 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max_iter reached after 283 seconds\n",
            "max_iter reached after 285 seconds\n",
            "max_iter reached after 285 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=250)]: Done   4 out of  23 | elapsed:  4.8min remaining: 22.6min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max_iter reached after 286 seconds\n",
            "max_iter reached after 286 seconds\n",
            "max_iter reached after 286 seconds\n",
            "max_iter reached after 286 seconds\n",
            "max_iter reached after 286 seconds\n",
            "max_iter reached after 287 seconds\n",
            "max_iter reached after 287 seconds\n",
            "max_iter reached after 287 seconds\n",
            "max_iter reached after 287 seconds\n",
            "max_iter reached after 287 seconds\n",
            "max_iter reached after 287 seconds\n",
            "max_iter reached after 288 seconds\n",
            "max_iter reached after 288 seconds\n",
            "max_iter reached after 288 seconds\n",
            "max_iter reached after 288 seconds\n",
            "max_iter reached after 288 seconds\n",
            "max_iter reached after 288 seconds\n",
            "max_iter reached after 288 seconds\n",
            "max_iter reached after 289 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=250)]: Done  23 out of  23 | elapsed:  4.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=50,\n",
              "                   multi_class='ovr', n_jobs=250, penalty='l2',\n",
              "                   random_state=None, solver='sag', tol=0.0001, verbose=1,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Au7FiZb4GYmR"
      },
      "source": [
        "* Predicting the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YtJLPWRMGYmS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13557762-5a6f-464e-a370-335fb68f6a62"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predLr = clf.predict(testX) #Predicting on the test dataset\n",
        "print(accuracy_score(predLr, testY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7021863041558511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2fMvmmPK1ib",
        "colab_type": "text"
      },
      "source": [
        "**Gaussian Naive Bayes Classifier**\n",
        "\n",
        "Gaussian Naïve Bayes classifier assumes that the data from each label is drawn from a simple Gaussian distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKDVPJ88zFOT",
        "colab_type": "text"
      },
      "source": [
        "* Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p503nSGJK0w5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8d8f450-ed25-46a3-b68e-c9b83e496824"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "#Create a Gaussian Naive Bayes Classifier\n",
        "gnb = GaussianNB()\n",
        "\n",
        "#Train the model on test data\n",
        "gnb.fit(trainX,trainY)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkX86MyYhqGI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "* Predicting the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8kVb4nWLN4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ced3d4f-1fe5-45d5-f83c-6bc5d446f1ce"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "prednb = gnb.predict(testX)\n",
        "print(accuracy_score(prednb, testY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9428094450974378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8CMmkkJL6Ox",
        "colab_type": "text"
      },
      "source": [
        "**MLP (Multilayer Perceptron)**\n",
        "\n",
        "A multilayer perceptron (MLP) is a class of feedforward artificial neural network (ANN). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVq4hxvgzKHb",
        "colab_type": "text"
      },
      "source": [
        "* Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UVVY1uY6n-b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "bfd7d4ca-6325-4aa2-fdf3-6380f56abe28"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "#Create a Multi-Layer Perceptron\n",
        "mlpclf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "hidden_layer_sizes=(5, 3), random_state=1)\n",
        "mlpclf.fit(trainX,trainY)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(5, 3), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=1, shuffle=True, solver='lbfgs',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EX_wECOhgjl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "* Predicting the accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxohAYua6sEt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e687deea-0a92-44d0-c42a-98338da1572d"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "predmlp=mlpclf.predict(testX)\n",
        "print(accuracy_score(predmlp, testY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0007595765309378197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSxmMGYepD8U",
        "colab_type": "text"
      },
      "source": [
        "**Decision Tree Classifier**\n",
        "\n",
        "The decision tree classifier creates the classification model by building a decision tree. Each node in the tree specifies a test on an attribute, each branch descending from that node corresponds to one of the possible values for that attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay8RHI5mBNR1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4a1d4ad7-6c58-40e8-b9fe-c073116c3293"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import zero_one_loss\n",
        "\n",
        "# Training\n",
        "print (\"Training model..........\")\n",
        "dtclf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None)\n",
        "\n",
        "trained_model = dtclf.fit(trainX,trainY)\n",
        "\n",
        "print (\"Score: \", trained_model.score(trainX, trainY))\n",
        "\n",
        "# Predicting\n",
        "print (\"Predicting\")\n",
        "y_pred = dtclf.predict(testX)\n",
        "\n",
        "print (\"Computing performance metrics\")\n",
        "\n",
        "print (\"Error: \", zero_one_loss(testY, y_pred))\n",
        "print(\"Accuracy: \", accuracy_score(y_pred, testY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model\n",
            "Score:  0.9999958481235283\n",
            "Predicting\n",
            "Computing performance metrics\n",
            "Error:  0.011138397314104487\n",
            "Accuracy:  0.9888616026858955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA50Kb2rlSiT",
        "colab_type": "text"
      },
      "source": [
        "**KNN (K-Nearest Neighbour) Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsGkqZ1fBeq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "955d553e-1713-457d-fb60-1823a3c6e91a"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import zero_one_loss\n",
        "\n",
        "print(\"Training..........\")\n",
        "KNNclf = KNeighborsClassifier(1, n_jobs=-1)\n",
        "KNNclf.fit(trainX, trainY)\n",
        "# Predicting\n",
        "predknn = KNNclf.predict(testX)\n",
        "\n",
        "print (\"Computing performance metrics\")\n",
        "\n",
        "print (\"Error: \", zero_one_loss(testY, predknn))\n",
        "print(\"Accuracy: \", accuracy_score(testY, predknn))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training..........\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoRauvtgpyv-",
        "colab_type": "text"
      },
      "source": [
        "### **Deep Neural Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnG7YKpx3DyJ",
        "colab_type": "text"
      },
      "source": [
        "A deep neural network (DNN) is an artificial neural network (ANN) with multiple layers between the input and output layers. The DNN finds the correct mathematical manipulation to turn the input into the output, whether it be a linear relationship or a non-linear relationship.\n",
        "\n",
        "> Note : We are evaluating neural networks with several different hidden layers configuration. Current epochs has been set to 50, one can change it accordingly.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErFYg0-iwtu1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "be0d779f-f984-458e-eb95-2b7f35d3a422"
      },
      "source": [
        "%cd /content\n",
        "!rm -rf 'anomaly-detection-system'\n",
        "!git clone https://github.com/piyush-palta/anomaly-detection-system"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'anomaly-detection-system'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 8 (delta 1), reused 5 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (8/8), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V1jf7e-0VfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "\n",
        "traindata = pd.read_csv('/content/anomaly-detection-system/dataset/training.csv', header=None)\n",
        "testdata = pd.read_csv('/content/anomaly-detection-system/dataset/testing.csv', header=None)\n",
        "\n",
        "\n",
        "X = traindata.iloc[:,1:42]\n",
        "Y = traindata.iloc[:,0]\n",
        "C = testdata.iloc[:,0]\n",
        "T = testdata.iloc[:,1:42]\n",
        "\n",
        "trainX = np.array(X)\n",
        "testT = np.array(T)\n",
        "\n",
        "trainX.astype(float)\n",
        "testT.astype(float)\n",
        "\n",
        "scaler = Normalizer().fit(trainX)\n",
        "trainX = scaler.transform(trainX)\n",
        "\n",
        "scaler = Normalizer().fit(testT)\n",
        "testT = scaler.transform(testT)\n",
        "\n",
        "y_train = np.array(Y)\n",
        "y_test = np.array(C)\n",
        "\n",
        "X_train = np.array(trainX)\n",
        "X_test = np.array(testT)\n",
        "\n",
        "batch_size = 64"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot7tI_eIr4qF",
        "colab_type": "text"
      },
      "source": [
        "**Deep Neural Networks with 1 Hidden Layer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-KEm_RRpx6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2ef102ba-6ff7-457f-b5bb-98d11493ae12"
      },
      "source": [
        "# 1. define the network\n",
        "model = Sequential()\n",
        "model.add(Dense(512,input_dim=41,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=50)\n",
        "model.save(\"model_nn1.hdf5\")\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "7720/7720 [==============================] - 24s 3ms/step - loss: 0.1077 - accuracy: 0.9574 - val_loss: 0.2801 - val_accuracy: 0.9133\n",
            "Epoch 2/2\n",
            "7720/7720 [==============================] - 25s 3ms/step - loss: 0.0441 - accuracy: 0.9845 - val_loss: 0.3179 - val_accuracy: 0.9138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rYXqaNzv1R80"
      },
      "source": [
        "**Deep Neural Networks with 2 Hidden Layer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slu4yeOTz34H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a888824b-4be5-4ddc-aebb-afd6a4ddae6b"
      },
      "source": [
        "# define the network\n",
        "model = Sequential()\n",
        "model.add(Dense(512,input_dim=41,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(256,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=50)\n",
        "model.save(\"model_nn2.hdf5\")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7720/7720 [==============================] - 27s 3ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.6377 - val_accuracy: 0.9221\n",
            "Epoch 2/5\n",
            "7720/7720 [==============================] - 27s 4ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.5979 - val_accuracy: 0.9251\n",
            "Epoch 3/5\n",
            "7720/7720 [==============================] - 27s 4ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.6695 - val_accuracy: 0.9249\n",
            "Epoch 4/5\n",
            "7720/7720 [==============================] - 26s 3ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 1.1172 - val_accuracy: 0.9241\n",
            "Epoch 5/5\n",
            "7720/7720 [==============================] - 26s 3ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.9037 - val_accuracy: 0.9265\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe6bc9cfb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6On5ajIZ11Pl"
      },
      "source": [
        "**Deep Neural Networks with 3 Hidden Layer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO82AFsv2AO4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "340ea097-8c35-4568-da15-6e2d17dd0ba7"
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024,input_dim=41,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(768,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(512,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=50)\n",
        "model.save(\"model_nn3.hdf5\")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7720/7720 [==============================] - 30s 4ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.7391 - val_accuracy: 0.9225\n",
            "Epoch 2/5\n",
            "7720/7720 [==============================] - 30s 4ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.5614 - val_accuracy: 0.9255\n",
            "Epoch 3/5\n",
            "7720/7720 [==============================] - 30s 4ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.9527 - val_accuracy: 0.9245\n",
            "Epoch 4/5\n",
            "7720/7720 [==============================] - 30s 4ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.6288 - val_accuracy: 0.9244\n",
            "Epoch 5/5\n",
            "7720/7720 [==============================] - 30s 4ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.8224 - val_accuracy: 0.9255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s-rdMJnb11_-"
      },
      "source": [
        "**Deep Neural Networks with 4 Hidden Layer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzY2Gmr52TZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1024,input_dim=41,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(768,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(512,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(256,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=50)\n",
        "model.save(\"model_nn4.hdf5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nd3c3wVY12Hp"
      },
      "source": [
        "**Deep Neural Networks with 5 Hidden Layer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV5DjWtJ2g8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "dea38205-7c82-4288-8821-f6243e44fb36"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1024,input_dim=41,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(768,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(512,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(256,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(128,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=50)\n",
        "model.save(\"model_nn5.hdf5\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "7720/7720 [==============================] - 33s 4ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.6161 - val_accuracy: 0.9222\n",
            "Epoch 2/2\n",
            "7720/7720 [==============================] - 32s 4ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 1.1238 - val_accuracy: 0.9237\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}